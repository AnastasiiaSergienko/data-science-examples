{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data processing and linear regression with Exasol\n",
    "\n",
    "This tutorial is for users who want to use Exasol as a data source for training a linear regression model. \n",
    "However, the data analyzing and processing part can also be interesting to anyone who's looking for the information how to prepare a dataset for a training. \n",
    "\n",
    "In this tutorial we will discuss the following topics:\n",
    "\n",
    "- Part 1. How to import a dataset from CSV file to Exasol database.\n",
    "- Part 2. How to analyze the data in the table.\n",
    "- Part 3. How to prepare data for using it in linear regression model.\n",
    "- Part 4. How to create and train a model.\n",
    "\n",
    "The model in this example will predict a flight's delay.\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "The users are assumed to have a basic understanding of Exasol, SQL and also basic Python programming knowledge.\n",
    "\n",
    "## Part 1. Importing data\n",
    "\n",
    "In our tutorial we use `Flights.csv` file which provides information about the U.S. domestic flights from 1987 to 2019 year.\n",
    "The file contains more than 184 millions rows and 109 columns.\n",
    "\n",
    "As the CSV file is too big, - more than 80 GB - we can't work with it directly importing is as a Pandas DataFrame.\n",
    "That's the reason why we need to use a database as a warehouse and also a workbench for a future data transformation process.\n",
    "\n",
    "So, the first step: **we start an Exasol Database**. \n",
    "For this tutorial we installed an Exasol Cloud Image using [Exasol Cloud Wizard](https://cloudtools.exasol.com/#/).\n",
    "If you want to know more about Exasol Cloud Wizard, you can read an article about how to use this tool in our [blog](https://www.exasol.com/en/blog/building-clusters-in-the-sky-exasol-cloud-wizard/).\n",
    "A local Exasol node was not a good option in our case, because a local machine with this node proceeds data significantly slower than the cloud image.\n",
    "\n",
    "The second step: **import data from CSV file to Exasol's table**. \n",
    "\n",
    "1. We create an SQL CREATE TABLE statement and put it in a separate file named `flights.sql`.\n",
    "Our table will have 109 columns according to the CSV file. Here is a part of the query:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CREATE OR REPLACE TABLE \"FLIGHTS\" (\"YEAR\" INTEGER, \"QUARTER\" INTEGER, \"MONTH\" INTEGER, \"DAY_OF_MONTH\" INTEGER, \"DAY_OF_WEEK\" DECIMAL(1,0), ... , ...);\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. We connect to the Exasol, create a new schema and create a new table using the statement above.\n",
    "\n",
    " For connection and executing queries we use [pyexasol](https://github.com/badoo/pyexasol) library.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pyexasol\n",
    "\n",
    "connection = pyexasol.connect(dsn='host:port', user='username', password='password', compression=True)\n",
    "\n",
    "connection.execute(\"CREATE SCHEMA IF NOT EXISTS {schema_name};\".format(schema_name=\"FLIGHTS\"))\n",
    "connection.open_schema(\"FLIGHTS\")\n",
    "create_table_query = open('flights.sql', 'r')\n",
    "for line in create_table_query:\n",
    "    connection.execute(query=line)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " 3. After table is ready, we are importing the CSV file's content to the table using pyexasol. \n",
    "    The file is stored in Google Storage because of its size, so we only use a link to the file."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "connection.execute(\"IMPORT INTO {table_name} FROM CSV AT '{file_path}' FILE '{file_name}' \"\n",
    "            \"COLUMN SEPARATOR = '{column_separator}' SKIP = 1  \"\n",
    "            \"ERRORS INTO error_table (CURRENT_TIMESTAMP) REJECT LIMIT UNLIMITED ERRORS\".format(\n",
    "                table_name=\"FLIGHTS\", file_path=\"https://storage.googleapis.com/our/path/\", file_name=\"flights.single.csv.gz\", column_separator=\",\"))\n",
    "connection.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now you should be able to find all the data in the Exasol's table. \n",
    "Below you can see a python class that is doing the process described above."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import simplestopwatch\n",
    "\n",
    "\n",
    "class CsvImporter:\n",
    "    def __init__(self, connection):\n",
    "        self.connection = connection\n",
    "\n",
    "    def import_file(self, sql_create_table_file, schema_name, table_name, file_path, file_name, column_separator):\n",
    "        self.__handle_schema(self.connection, schema_name)\n",
    "        self.__execute_create_table(sql_create_table_file)\n",
    "        self.__run_import_command(self.connection, table_name, file_path, file_name, column_separator)\n",
    "\n",
    "    def __execute_create_table(self, sql_create_table_file):\n",
    "        query = open(sql_create_table_file, 'r')\n",
    "        for line in query:\n",
    "            self.connection.execute(query=line)\n",
    "\n",
    "    def __handle_schema(self, connection, schema_name):\n",
    "        connection.execute(\"CREATE SCHEMA IF NOT EXISTS \" + schema_name + \";\")\n",
    "        connection.open_schema(schema_name)\n",
    "\n",
    "    def __run_import_command(self, connection, table_name, file_path, file_name, column_separator):\n",
    "        timer = simplestopwatch.Timer()\n",
    "        connection.execute(\n",
    "            \"IMPORT INTO {table_name} FROM CSV AT '{file_path}' FILE '{file_name}' \"\n",
    "            \"COLUMN SEPARATOR = '{column_separator}' SKIP = 1  \"\n",
    "            \"ERRORS INTO error_table (CURRENT_TIMESTAMP) REJECT LIMIT UNLIMITED ERRORS\".format(\n",
    "                table_name=table_name, file_path=file_path, file_name=file_name, column_separator=column_separator))\n",
    "        timer.stop()\n",
    "        print(\"Imported in \" + str(timer))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 2. Analyzing data\n",
    "\n",
    "Now when we have a dataset in the Exasol table, we can start analyzing data.\n",
    "\n",
    "First, we should take a look at the columns list and decide which of them we would use for the model's training.\n",
    "\n",
    "### How do we decide which columns we need?   \n",
    "\n",
    "We just look at the columns one by one and judge whether it can be helpful for prediction or not.\n",
    "A few examples of columns which we decided to use in our model for delay prediction:\n",
    "- Day of week\n",
    "- Departure airport\n",
    "- Arrival airport etc.\n",
    "\n",
    "And also a few column which we decided NOT to use:\n",
    "- Flight number: a unique number that represents an exact flight.\n",
    "- Delay reason: we don't need a reason to predict a delay.\n",
    "- Cancelled: this information doesn't affect delay.\n",
    "\n",
    "### How to handle columns with similar information?\n",
    "\n",
    "As we don't need the repeated information, we should select only one column which suits best to the model.\n",
    "For example, we have 3 columns:\n",
    "-Origin Airport: name of an airport as a string.\n",
    "-Origin Airport ID: an identification number assigned by US DOT to identify a unique airport. \n",
    "-Origin Airport Sequence ID: an identification number assigned by US DOT to identify a unique airport at a given point of time.\n",
    "\n",
    "These columns encode the same information but in different ways. We would select the second one - Origin Airport ID, for the model.\n",
    "The first reason - it's numeric. And the second - this code is more stable than the Origin Airport Sequence ID as it won't change with the time.\n",
    "\n",
    "### Analyzing selected columns\n",
    "\n",
    "The next step is to collect data about the content of the selected columns. \n",
    "Here is a small list which can give you an idea how to analyze a column:\n",
    "\n",
    "1. How many null values does the column contain?\n",
    "2. How is the data represented in the column: string, number, date, etc?\n",
    "3. How many distinct values does the column contain?\n",
    "4. What are the maximum and minimum values (for numbers)?\n",
    "\n",
    "For our example we collected data using pyexasol and then created charts with plotly library."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import plotly.express as plotly\n",
    "import pyexasol\n",
    "\n",
    "\n",
    "class Stats:\n",
    "    def get_categorical_stats(self, connection: pyexasol.connection, schema_name: str, table_name: str,\n",
    "                              column_name: str):\n",
    "        connection.openSchema(schema_name)\n",
    "        sum_of_distinct_values = self.__get_query_result(connection,\n",
    "                                                         'SELECT count (distinct \"{column_name}\") from {table_name};'\n",
    "                                                         .format(column_name=column_name, table_name=table_name))\n",
    "        sum_of_nulls = self.__get_query_result(connection,\n",
    "                                               'SELECT COUNT(*) from  {table_name} WHERE \"{column_name}\" IS NULL;'\n",
    "                                               .format(table_name=table_name, column_name=column_name))\n",
    "        max_value = self.__get_query_result(connection, 'SELECT MAX(\"{column_name}\") from {table_name};'\n",
    "                                            .format(column_name=column_name, table_name=table_name))\n",
    "        min_value = self.__get_query_result(connection, 'SELECT MIN(\"{column_name}\") from {table_name};'\n",
    "                                            .format(column_name=column_name, table_name=table_name))\n",
    "\n",
    "        result_set = connection.export_to_pandas(\n",
    "            'SELECT DISTINCT \"{column_name}\", COUNT(\"{column_name}\") as sum_of_distinct_values from {table_name} '\n",
    "            'GROUP BY \"{column_name}\" ORDER BY \"{column_name}\";'\n",
    "                .format(column_name=column_name, table_name=table_name))\n",
    "\n",
    "        bar = plotly.bar(result_set, x=(column_name), y=\"SUM_OF_DISTINCT_VALUES\",\n",
    "                         title=\"Column: \" + column_name + \", sum of dist values=\" + str(\n",
    "                             sum_of_distinct_values) + \", nulls=\" + str(sum_of_nulls) + \", max value=\" + str(\n",
    "                             max_value) + \", min value=\" + str(min_value))\n",
    "        bar.layout.xaxis.type = 'category'\n",
    "        return bar\n",
    "\n",
    "    def __get_query_result(self, connection: pyexasol.connection, query: str):\n",
    "        iterable_query_result = connection.execute(query)\n",
    "        counter = 0\n",
    "        for row in iterable_query_result:\n",
    "            counter = row[0]\n",
    "        return counter\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And here is an example of a chart:\n",
    "<img src=\"img/img1.png\">"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}